{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5ee6260-5839-479b-b1bb-f280134a18c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68e9918e-160e-4eef-abab-591eeb1e58ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.66610</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.16740</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.63830</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.52280</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.45520</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>0.40614</td>\n",
       "      <td>1.34920</td>\n",
       "      <td>-1.4501</td>\n",
       "      <td>-0.55949</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>-1.38870</td>\n",
       "      <td>-4.87730</td>\n",
       "      <td>6.4774</td>\n",
       "      <td>0.34179</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>-3.75030</td>\n",
       "      <td>-13.45860</td>\n",
       "      <td>17.5932</td>\n",
       "      <td>-2.77710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>-3.56370</td>\n",
       "      <td>-8.38270</td>\n",
       "      <td>12.3930</td>\n",
       "      <td>-1.28230</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>-2.54190</td>\n",
       "      <td>-0.65804</td>\n",
       "      <td>2.6842</td>\n",
       "      <td>1.19520</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1372 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1        2        3  4\n",
       "0     3.62160   8.66610  -2.8073 -0.44699  0\n",
       "1     4.54590   8.16740  -2.4586 -1.46210  0\n",
       "2     3.86600  -2.63830   1.9242  0.10645  0\n",
       "3     3.45660   9.52280  -4.0112 -3.59440  0\n",
       "4     0.32924  -4.45520   4.5718 -0.98880  0\n",
       "...       ...       ...      ...      ... ..\n",
       "1367  0.40614   1.34920  -1.4501 -0.55949  1\n",
       "1368 -1.38870  -4.87730   6.4774  0.34179  1\n",
       "1369 -3.75030 -13.45860  17.5932 -2.77710  1\n",
       "1370 -3.56370  -8.38270  12.3930 -1.28230  1\n",
       "1371 -2.54190  -0.65804   2.6842  1.19520  1\n",
       "\n",
       "[1372 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data_banknote_authentication.txt\", header=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1db3106b-d4ee-4293-a64b-2784d108f850",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = df[[0, 1, 2, 3]].values\n",
    "y_labels = df[4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98d3f576-f881-4aed-acec-f343af780250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1372, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f499b3ad-ef1d-4f2b-a773-2e0163660731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([762, 610])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# 762 0;  610 1\n",
    "np.bincount(y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7fa4e30-7739-4ab7-84b1-b4579de47081",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class MyDataSet(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.features = torch.tensor(X, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.features[index]\n",
    "        y = self.labels[index]\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8709bf28-c146-44c5-952e-e4e42b01032a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1097"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = int(X_features.shape[0] * 0.8)\n",
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "beeb6646-10d4-4521-90a9-1a125a4e8882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "275"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_size = X_features.shape[0] - train_size\n",
    "val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "440f5ad2-0187-4a3a-98c5-4578ae1d2c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "dataset = MyDataSet(X_features, y_labels)\n",
    "\n",
    "torch.manual_seed(1)\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset = train_set,\n",
    "    batch_size = 10,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset = val_set,\n",
    "    batch_size = 10,\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19d05b67-0aa2-4357-90ae-e8e307532a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(num_features, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear(x)\n",
    "        probas = torch.sigmoid(logits)\n",
    "        return probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5111399-2f3b-4e88-8300-fa6d2846ff43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/020 | Batch 000/110 | Loss: 1.30\n",
      "Epoch: 001/020 | Batch 020/110 | Loss: 0.12\n",
      "Epoch: 001/020 | Batch 040/110 | Loss: 0.23\n",
      "Epoch: 001/020 | Batch 060/110 | Loss: 0.03\n",
      "Epoch: 001/020 | Batch 080/110 | Loss: 0.02\n",
      "Epoch: 001/020 | Batch 100/110 | Loss: 0.03\n",
      "Epoch: 002/020 | Batch 000/110 | Loss: 0.08\n",
      "Epoch: 002/020 | Batch 020/110 | Loss: 0.02\n",
      "Epoch: 002/020 | Batch 040/110 | Loss: 0.12\n",
      "Epoch: 002/020 | Batch 060/110 | Loss: 0.05\n",
      "Epoch: 002/020 | Batch 080/110 | Loss: 0.04\n",
      "Epoch: 002/020 | Batch 100/110 | Loss: 0.06\n",
      "Epoch: 003/020 | Batch 000/110 | Loss: 0.02\n",
      "Epoch: 003/020 | Batch 020/110 | Loss: 0.04\n",
      "Epoch: 003/020 | Batch 040/110 | Loss: 0.02\n",
      "Epoch: 003/020 | Batch 060/110 | Loss: 0.14\n",
      "Epoch: 003/020 | Batch 080/110 | Loss: 0.04\n",
      "Epoch: 003/020 | Batch 100/110 | Loss: 0.01\n",
      "Epoch: 004/020 | Batch 000/110 | Loss: 0.01\n",
      "Epoch: 004/020 | Batch 020/110 | Loss: 0.01\n",
      "Epoch: 004/020 | Batch 040/110 | Loss: 0.11\n",
      "Epoch: 004/020 | Batch 060/110 | Loss: 0.05\n",
      "Epoch: 004/020 | Batch 080/110 | Loss: 0.00\n",
      "Epoch: 004/020 | Batch 100/110 | Loss: 0.05\n",
      "Epoch: 005/020 | Batch 000/110 | Loss: 0.04\n",
      "Epoch: 005/020 | Batch 020/110 | Loss: 0.04\n",
      "Epoch: 005/020 | Batch 040/110 | Loss: 0.00\n",
      "Epoch: 005/020 | Batch 060/110 | Loss: 0.06\n",
      "Epoch: 005/020 | Batch 080/110 | Loss: 0.02\n",
      "Epoch: 005/020 | Batch 100/110 | Loss: 0.02\n",
      "Epoch: 006/020 | Batch 000/110 | Loss: 0.04\n",
      "Epoch: 006/020 | Batch 020/110 | Loss: 0.02\n",
      "Epoch: 006/020 | Batch 040/110 | Loss: 0.20\n",
      "Epoch: 006/020 | Batch 060/110 | Loss: 0.01\n",
      "Epoch: 006/020 | Batch 080/110 | Loss: 0.00\n",
      "Epoch: 006/020 | Batch 100/110 | Loss: 0.13\n",
      "Epoch: 007/020 | Batch 000/110 | Loss: 0.00\n",
      "Epoch: 007/020 | Batch 020/110 | Loss: 0.00\n",
      "Epoch: 007/020 | Batch 040/110 | Loss: 0.01\n",
      "Epoch: 007/020 | Batch 060/110 | Loss: 0.00\n",
      "Epoch: 007/020 | Batch 080/110 | Loss: 0.03\n",
      "Epoch: 007/020 | Batch 100/110 | Loss: 0.04\n",
      "Epoch: 008/020 | Batch 000/110 | Loss: 0.10\n",
      "Epoch: 008/020 | Batch 020/110 | Loss: 0.01\n",
      "Epoch: 008/020 | Batch 040/110 | Loss: 0.01\n",
      "Epoch: 008/020 | Batch 060/110 | Loss: 0.02\n",
      "Epoch: 008/020 | Batch 080/110 | Loss: 0.01\n",
      "Epoch: 008/020 | Batch 100/110 | Loss: 0.02\n",
      "Epoch: 009/020 | Batch 000/110 | Loss: 0.02\n",
      "Epoch: 009/020 | Batch 020/110 | Loss: 0.01\n",
      "Epoch: 009/020 | Batch 040/110 | Loss: 0.00\n",
      "Epoch: 009/020 | Batch 060/110 | Loss: 0.04\n",
      "Epoch: 009/020 | Batch 080/110 | Loss: 0.03\n",
      "Epoch: 009/020 | Batch 100/110 | Loss: 0.04\n",
      "Epoch: 010/020 | Batch 000/110 | Loss: 0.03\n",
      "Epoch: 010/020 | Batch 020/110 | Loss: 0.01\n",
      "Epoch: 010/020 | Batch 040/110 | Loss: 0.00\n",
      "Epoch: 010/020 | Batch 060/110 | Loss: 0.02\n",
      "Epoch: 010/020 | Batch 080/110 | Loss: 0.02\n",
      "Epoch: 010/020 | Batch 100/110 | Loss: 0.00\n",
      "Epoch: 011/020 | Batch 000/110 | Loss: 0.00\n",
      "Epoch: 011/020 | Batch 020/110 | Loss: 0.00\n",
      "Epoch: 011/020 | Batch 040/110 | Loss: 0.14\n",
      "Epoch: 011/020 | Batch 060/110 | Loss: 0.01\n",
      "Epoch: 011/020 | Batch 080/110 | Loss: 0.07\n",
      "Epoch: 011/020 | Batch 100/110 | Loss: 0.00\n",
      "Epoch: 012/020 | Batch 000/110 | Loss: 0.05\n",
      "Epoch: 012/020 | Batch 020/110 | Loss: 0.01\n",
      "Epoch: 012/020 | Batch 040/110 | Loss: 0.00\n",
      "Epoch: 012/020 | Batch 060/110 | Loss: 0.00\n",
      "Epoch: 012/020 | Batch 080/110 | Loss: 0.04\n",
      "Epoch: 012/020 | Batch 100/110 | Loss: 0.00\n",
      "Epoch: 013/020 | Batch 000/110 | Loss: 0.01\n",
      "Epoch: 013/020 | Batch 020/110 | Loss: 0.00\n",
      "Epoch: 013/020 | Batch 040/110 | Loss: 0.01\n",
      "Epoch: 013/020 | Batch 060/110 | Loss: 0.04\n",
      "Epoch: 013/020 | Batch 080/110 | Loss: 0.01\n",
      "Epoch: 013/020 | Batch 100/110 | Loss: 0.11\n",
      "Epoch: 014/020 | Batch 000/110 | Loss: 0.09\n",
      "Epoch: 014/020 | Batch 020/110 | Loss: 0.01\n",
      "Epoch: 014/020 | Batch 040/110 | Loss: 0.00\n",
      "Epoch: 014/020 | Batch 060/110 | Loss: 0.07\n",
      "Epoch: 014/020 | Batch 080/110 | Loss: 0.01\n",
      "Epoch: 014/020 | Batch 100/110 | Loss: 0.06\n",
      "Epoch: 015/020 | Batch 000/110 | Loss: 0.16\n",
      "Epoch: 015/020 | Batch 020/110 | Loss: 0.00\n",
      "Epoch: 015/020 | Batch 040/110 | Loss: 0.00\n",
      "Epoch: 015/020 | Batch 060/110 | Loss: 0.01\n",
      "Epoch: 015/020 | Batch 080/110 | Loss: 0.00\n",
      "Epoch: 015/020 | Batch 100/110 | Loss: 0.19\n",
      "Epoch: 016/020 | Batch 000/110 | Loss: 0.00\n",
      "Epoch: 016/020 | Batch 020/110 | Loss: 0.00\n",
      "Epoch: 016/020 | Batch 040/110 | Loss: 0.00\n",
      "Epoch: 016/020 | Batch 060/110 | Loss: 0.01\n",
      "Epoch: 016/020 | Batch 080/110 | Loss: 0.00\n",
      "Epoch: 016/020 | Batch 100/110 | Loss: 0.01\n",
      "Epoch: 017/020 | Batch 000/110 | Loss: 0.00\n",
      "Epoch: 017/020 | Batch 020/110 | Loss: 0.02\n",
      "Epoch: 017/020 | Batch 040/110 | Loss: 0.01\n",
      "Epoch: 017/020 | Batch 060/110 | Loss: 0.04\n",
      "Epoch: 017/020 | Batch 080/110 | Loss: 0.04\n",
      "Epoch: 017/020 | Batch 100/110 | Loss: 0.01\n",
      "Epoch: 018/020 | Batch 000/110 | Loss: 0.02\n",
      "Epoch: 018/020 | Batch 020/110 | Loss: 0.00\n",
      "Epoch: 018/020 | Batch 040/110 | Loss: 0.01\n",
      "Epoch: 018/020 | Batch 060/110 | Loss: 0.01\n",
      "Epoch: 018/020 | Batch 080/110 | Loss: 0.01\n",
      "Epoch: 018/020 | Batch 100/110 | Loss: 0.00\n",
      "Epoch: 019/020 | Batch 000/110 | Loss: 0.00\n",
      "Epoch: 019/020 | Batch 020/110 | Loss: 0.01\n",
      "Epoch: 019/020 | Batch 040/110 | Loss: 0.00\n",
      "Epoch: 019/020 | Batch 060/110 | Loss: 0.00\n",
      "Epoch: 019/020 | Batch 080/110 | Loss: 0.00\n",
      "Epoch: 019/020 | Batch 100/110 | Loss: 0.01\n",
      "Epoch: 020/020 | Batch 000/110 | Loss: 0.02\n",
      "Epoch: 020/020 | Batch 020/110 | Loss: 0.03\n",
      "Epoch: 020/020 | Batch 040/110 | Loss: 0.02\n",
      "Epoch: 020/020 | Batch 060/110 | Loss: 0.00\n",
      "Epoch: 020/020 | Batch 080/110 | Loss: 0.00\n",
      "Epoch: 020/020 | Batch 100/110 | Loss: 0.00\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "torch.manual_seed(1)\n",
    "model = LogisticRegression(num_features=4)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.2) ## FILL IN VALUE\n",
    "\n",
    "num_epochs = 20  ## FILL IN VALUE\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    model = model.train()\n",
    "    for batch_idx, (features, class_labels) in enumerate(train_loader):\n",
    "\n",
    "        probas = model(features)\n",
    "        \n",
    "        loss = F.binary_cross_entropy(probas, class_labels.view(probas.shape))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        ### LOGGING\n",
    "        if not batch_idx % 20: # log every 20th batch\n",
    "            print(f'Epoch: {epoch+1:03d}/{num_epochs:03d}'\n",
    "                   f' | Batch {batch_idx:03d}/{len(train_loader):03d}'\n",
    "                   f' | Loss: {loss:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec22a243-32d8-4a08-a79a-5d3d06bea11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model, dataloader):\n",
    "\n",
    "    model = model.eval()\n",
    "    \n",
    "    correct = 0.0\n",
    "    total_examples = 0\n",
    "    \n",
    "    for idx, (features, class_labels) in enumerate(dataloader):\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            probas = model(features)\n",
    "        \n",
    "        pred = torch.where(probas > 0.5, 1, 0)\n",
    "        lab = class_labels.view(pred.shape).to(pred.dtype)\n",
    "\n",
    "        compare = lab == pred\n",
    "        correct += torch.sum(compare)\n",
    "        total_examples += len(compare)\n",
    "\n",
    "    return correct / total_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a6d714d-ce66-4988-ba6f-2e570b7c2987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.18%\n"
     ]
    }
   ],
   "source": [
    "train_acc = compute_accuracy(model, train_loader)\n",
    "print(f\"Accuracy: {train_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e53983af-0b03-4b1b-81e5-e0dc57cb1a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1372, 4)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5209437d-92a9-427d-8cbf-239dd0ac5bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = torch.zeros(X_features.shape[1])\n",
    "\n",
    "for x, y in train_loader:\n",
    "    train_mean += x.sum(dim = 0)\n",
    "\n",
    "train_mean = train_mean / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "34094caa-0656-4c0d-83ee-bca8d912d4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_std = torch.zeros(X_features.shape[1])\n",
    "for x, y in train_loader:\n",
    "    train_std += ((x - train_mean)**2).sum(dim=0)\n",
    "\n",
    "train_std = torch.sqrt(train_std / (len(train_set)-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "73f6e4ab-36f1-494a-8774-cc618b9a4435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature means: tensor([  3.8440,  18.6294,  14.8823, -11.9659])\n",
      "Feature std. devs: tensor([ 4.4875, 17.7838, 14.0961, 10.9746])\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature means:\", train_mean)\n",
    "print(\"Feature std. devs:\", train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18dd9de-68ef-45e4-9997-1af78eed0746",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
