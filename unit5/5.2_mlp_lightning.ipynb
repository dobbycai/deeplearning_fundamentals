{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:00<00:00, 17.8MB/s]\n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.73MB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:00<00:00, 21.2MB/s]\n",
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 2.27MB/s]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    root = \"./mnist\", train = True, transform = transforms.ToTensor(), download = True\n",
    ")\n",
    "\n",
    "test_dataset = datasets.MNIST(\n",
    "    root = \"./mnist\", train = False, transform = transforms.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a9a5744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f461a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90530ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validation set\n",
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "train_dataset, val_dataset = random_split(train_dataset, lengths=[55000, 5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb1a2583",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset = train_dataset,\n",
    "    batch_size= 64,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset = val_dataset,\n",
    "    batch_size = 64,\n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset = test_dataset,\n",
    "    batch_size = 64,\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e379bf60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]]]),\n",
       " tensor([2, 2, 4, 4, 1, 6, 8, 9, 2, 2, 4, 4, 6, 0, 3, 1, 3, 3, 3, 6, 5, 8, 5, 9,\n",
       "         2, 2, 3, 0, 9, 3, 3, 1, 9, 9, 8, 4, 5, 1, 1, 8, 0, 9, 0, 9, 2, 0, 8, 8,\n",
       "         7, 6, 1, 3, 1, 3, 4, 4, 3, 6, 6, 3, 4, 6, 8, 1])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a2c8c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training label distribution:\n",
      "[(0, 5458), (1, 6165), (2, 5462), (3, 5637), (4, 5354), (5, 4980), (6, 5402), (7, 5745), (8, 5382), (9, 5415)]\n",
      "\n",
      "Validation label distribution:\n",
      "[(0, 465), (1, 577), (2, 496), (3, 494), (4, 488), (5, 441), (6, 516), (7, 520), (8, 469), (9, 534)]\n",
      "\n",
      "Test label distribution:\n",
      "[(0, 980), (1, 1135), (2, 1032), (3, 1010), (4, 982), (5, 892), (6, 958), (7, 1028), (8, 974), (9, 1009)]\n"
     ]
    }
   ],
   "source": [
    "# check label distribution\n",
    "from collections import Counter\n",
    "\n",
    "train_counter = Counter()\n",
    "for images, labels in train_loader:\n",
    "    train_counter.update(labels.tolist())\n",
    "print(\"\\nTraining label distribution:\")\n",
    "print(sorted(train_counter.items()))\n",
    "\n",
    "val_counter = Counter()\n",
    "for images, labels in val_loader:\n",
    "    val_counter.update(labels.tolist())\n",
    "print(\"\\nValidation label distribution:\")\n",
    "print(sorted(val_counter.items()))\n",
    "\n",
    "test_counter = Counter()\n",
    "for images, labels in test_loader:\n",
    "    test_counter.update(labels.tolist())\n",
    "print(\"\\nTest label distribution:\")\n",
    "print(sorted(test_counter.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daf1c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority class: 1\n",
      "Accuracy when always predicting the majority class:\n",
      "0.11 (11.35%)\n"
     ]
    }
   ],
   "source": [
    "# Zero rule baseline (majority class classfier)\n",
    "majority_class = test_counter.most_common(1)[0]\n",
    "print(\"Majority class:\", majority_class[0])\n",
    "\n",
    "baseline_acc = majority_class[1] / sum(test_counter.values())\n",
    "print(\"Accuracy when always predicting the majority class:\")\n",
    "print(f\"{baseline_acc:.2f} ({baseline_acc*100:.2f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
